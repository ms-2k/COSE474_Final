%%%%%%%% ICML 2019 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2019} with \usepackage[nohyperref]{icml2019} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2019}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2019}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{COSE474-2023F: Final Project Proposal}

\begin{document}

\twocolumn[
\icmltitle{COSE474-2021F: Final Project \linebreak
           Machine Generated Journalism Detection Using Deep Learning}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2019
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Minseo Kim}{}
\end{icmlauthorlist}

%\icmlaffiliation{ku}{Department of Computer Science \& Engineering, Korea University, Seoul, Korea}


%\icmlcorrespondingauthor{the}{myemail@korea.ac.kr}
%\icmlcorrespondingauthor{Eee Pppp}{ep@eden.co.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

%\begin{abstract}
%This document provides a basic paper template and submission guidelines.
%Abstracts must be a single paragraph, ideally between 4--6 sentences long.
%Gross violations will trigger corrections at the camera-ready phase.
%\end{abstract}

\section{Introduction}
\quad In the recent years, Large Language Models (LLMs) have shown a remarkable ability to generate human-like text, making them a potentially valuable tool for automated journalism.
However, this same capability also poses several significant risks. \\
\null\quad Firstly, the widespread use of LLMs in journalism could lead to an increase in misinformation.
Given that these models generate content based on the data they are trained on,
they are susceptible to replicating and amplifying any biases present in that data.
This could potentially lead to the creation and dissemination of biased or misleading news articles. \\
\null\quad Secondly, the use of LLMs in journalism raises ethical concerns around plagiarism.
Since these models are trained on large quantities of data,
it is possible that they could inadvertently generate text that closely resembles existing articles,
violating intellectual property rights. \\
\null\quad Lastly, the advent of LLMs could potentially undermine public trust in journalism.
If audiences are unable to distinguish between human and machine generated content,
it could lead to a general distrust in the information they consume,
further exacerbating the current crisis of misinformation. \\
\null\quad On the other hand, while several models exist to classify English articles as human-written or machine generated,
the Korean language presents unique linguistic and structural facets which these models may not effectively capture.
Therefore, there is a pressing need to specifically train a model capable of classifying Korean articles.
This would contribute to ensuring the veracity of journalism in Korean language and help to maintain the integrity of information consumed by the public. \\
\null\quad To tackle this problem, this project aims to train a model capable of distinguishing human written and machine generated text.
In particular, the project aims to train a model capable of distinguishing human written and machine generated text in Korean, where the topic is relatively less explored. \\

\section{Source Code}
\null\quad The source code to this project can be found in the following github repository:
\begin{center} \url{https://github.com/ms-2k/COSE474_Final} \end{center}
\null\quad However, while the dataset was generated from publicly available data, to adhear to distribution rights they are not included in the github repository.

\section{Problem Definition}
\null\quad The primary objective of this research endeavor is to develop a computational model that can accurately differentiate between news articles authored by humans and those generated by machines, utilizing a transformer-based architecture.
The intended model should possess the capability to analyze and interpret any given news article text written in the Korean language and subsequently produce a binary output.
This binary output, in the form of a label, will indicate whether the given article is a product of human intellect or a result of machine generation. \\
\null\quad Despite the ambitious nature of this project, it is important to acknowledge the constraint of limited available computational resources.
Therefore, to overcome this limitation and ensure efficient use of resources, the final model will not be built from scratch.
Instead, we intend to fine-tune an existing model based on the BERT (Bidirectional Encoder Representations from Transformers) architecture.
This approach leverages the established capabilities of BERT while allowing us to tailor the model to our specific task of distinguishing between human-written and machine-generated news articles in Korean.

\section{Contribution}
\null\quad The sole main contributor to this project is Minseo Kim.

\section{Related Works and Baseline}
\null\quad While there are few studies on detecting machine generated Korean journalism, similar attempts have been made by numerous researchers to detect AI generated content in general.
Recent works such as RADAR (Hu et al., 2023) and DetectGPT (Mitchell et al., 2023) have attempted to distinguish human and machine generated text,
where the former in particular utilized an adversarial model with human generated text along with machine generated text generated and paraphrased from the human written text. \\
\null\quad Regrettably, these preceding works, while innovative in their own rights, have not been trained on Korean corpora.
This presents a significant challenge when attempting to utilize them as a baseline for comparison with our model.
The linguistic nuances and specificities inherent to the Korean language render these models less applicable in the context of our research.
Consequently, in order to establish a more suitable benchmark for evaluation, we have opted to use foundation models trained on a more diverse corpus as the baseline.
These foundation models, having been trained on diverse and extensive corpora, provide a more relevant and robust point of comparison for assessing our model's performance.

\section{Method}
\null\quad There were a two primary challenges that had to be addressed prior to training the model.
Firstly, it was difficult to obtain a large enough dataset consisting of both human written journalism and machine generated journalism.
The problem was especially apparent when limited to Korean corpora. \\
\null\quad Secondly, there are far more publicly available human written journalism than machine generated journalism.
This imbalance in data could lead to a class imbalance problem, where the model could be biased towards predicting articles as human written. \\
\null\quad To address the above problem we have decided to gather our own datasets by obtaining publicly available online Korean news, and then paraphrasing the articles with the help of an ensemble of large language models capable of text to text generation.
This will allow us to obtain a dataset that is equally comprised of human written and machine generated news, and potentially be large enough to train a robust model with.

\section{Overall Structure}
*insert image here later*


\section{Significance \& Novelty}


\section{Experiments}

\section{Dataset}
As described above the dataset is comprised of a corpus consisting of publicly available news articles from numerous Korean news outlets,
and corresponding machine generated news articles paraphrased from human written articles by an ensemble of large language models capable of text to text generation.

\section{Computing Resources}

\section{Experiment Setup}

\section{Comparison with Baseline}

\section{Conclusion}

\bibliographystyle{unsrt}
\bibliography{references}
Jiang, G. (2023, May 30). Is AI-generated content actually detectable?: College of Computer, Mathematical, and Natural Sciences: University of Maryland. College of Computer, Mathematical, and Natural Sciences | University of Maryland. https://cmns.umd.edu/news-events/news/ai-generated-content-actually-detectable 

Hu, X., Chen, P. Y., \& Ho, T. Y. (2023). RADAR: Robust AI-Text Detection via Adversarial Learning. arXiv preprint arXiv:2307.03838.

Mitchell, E., Lee, Y., Khazatsky, A., Manning, C. D., \& Finn, C. (2023). Detectgpt: Zero-shot machine-generated text detection using probability curvature. arXiv preprint arXiv:2301.11305.

kr-FinBert-SC, Kim, Eunhee and Hyopil Shin (2022). KR-FinBert: Fine-tuning KR-FinBert for Sentiment Analysis. huggingface \url{https://huggingface.co/snunlp/KR-FinBert-SC}
\end{document}